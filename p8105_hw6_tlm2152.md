P8105 Homework 6
================
Tucker Morgan (tlm2152)
12/4/2021

``` r
library(tidyverse)
library(modelr)
library(patchwork)
```

## Problem 1

``` r
birthweight_df <- read_csv("./Data/birthweight.csv")
```

    ## Rows: 4342 Columns: 20

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
str(birthweight_df)
```

    ## spec_tbl_df [4,342 × 20] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
    ##  $ babysex : num [1:4342] 2 1 2 1 2 1 2 2 1 1 ...
    ##  $ bhead   : num [1:4342] 34 34 36 34 34 33 33 33 36 33 ...
    ##  $ blength : num [1:4342] 51 48 50 52 52 52 46 49 52 50 ...
    ##  $ bwt     : num [1:4342] 3629 3062 3345 3062 3374 ...
    ##  $ delwt   : num [1:4342] 177 156 148 157 156 129 126 140 146 169 ...
    ##  $ fincome : num [1:4342] 35 65 85 55 5 55 96 5 85 75 ...
    ##  $ frace   : num [1:4342] 1 2 1 1 1 1 2 1 1 2 ...
    ##  $ gaweeks : num [1:4342] 39.9 25.9 39.9 40 41.6 ...
    ##  $ malform : num [1:4342] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ menarche: num [1:4342] 13 14 12 14 13 12 14 12 11 12 ...
    ##  $ mheight : num [1:4342] 63 65 64 64 66 66 72 62 61 64 ...
    ##  $ momage  : num [1:4342] 36 25 29 18 20 23 29 19 13 19 ...
    ##  $ mrace   : num [1:4342] 1 2 1 1 1 1 2 1 1 2 ...
    ##  $ parity  : num [1:4342] 3 0 0 0 0 0 0 0 0 0 ...
    ##  $ pnumlbw : num [1:4342] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ pnumsga : num [1:4342] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ ppbmi   : num [1:4342] 26.3 21.3 23.6 21.8 21 ...
    ##  $ ppwt    : num [1:4342] 148 128 137 127 130 115 105 119 105 145 ...
    ##  $ smoken  : num [1:4342] 0 0 1 10 1 0 0 0 0 4 ...
    ##  $ wtgain  : num [1:4342] 29 28 11 30 26 14 21 21 41 24 ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   babysex = col_double(),
    ##   ..   bhead = col_double(),
    ##   ..   blength = col_double(),
    ##   ..   bwt = col_double(),
    ##   ..   delwt = col_double(),
    ##   ..   fincome = col_double(),
    ##   ..   frace = col_double(),
    ##   ..   gaweeks = col_double(),
    ##   ..   malform = col_double(),
    ##   ..   menarche = col_double(),
    ##   ..   mheight = col_double(),
    ##   ..   momage = col_double(),
    ##   ..   mrace = col_double(),
    ##   ..   parity = col_double(),
    ##   ..   pnumlbw = col_double(),
    ##   ..   pnumsga = col_double(),
    ##   ..   ppbmi = col_double(),
    ##   ..   ppwt = col_double(),
    ##   ..   smoken = col_double(),
    ##   ..   wtgain = col_double()
    ##   .. )
    ##  - attr(*, "problems")=<externalptr>

``` r
na_check <- birthweight_df[rowSums(is.na(birthweight_df)) > 0,]
na_check
```

    ## # A tibble: 0 × 20
    ## # … with 20 variables: babysex <dbl>, bhead <dbl>, blength <dbl>, bwt <dbl>,
    ## #   delwt <dbl>, fincome <dbl>, frace <dbl>, gaweeks <dbl>, malform <dbl>,
    ## #   menarche <dbl>, mheight <dbl>, momage <dbl>, mrace <dbl>, parity <dbl>,
    ## #   pnumlbw <dbl>, pnumsga <dbl>, ppbmi <dbl>, ppwt <dbl>, smoken <dbl>,
    ## #   wtgain <dbl>

``` r
rm(na_check)
```

Looks like I will want to convert a handful of variables like `babysex`,
`frace`, `malform`, and `mrace` to factors instead of numeric vectors.
And it doesn’t seem like there are any NA values to account for before
analysis.

``` r
birthweight_df <- 
  birthweight_df %>% 
  mutate(babysex = factor(babysex,
                          levels = c(1, 2),
                          labels = c("male", "female"))) %>% 
  mutate(frace = factor(frace,
                        levels = c(1, 2, 3, 4, 8, 9),
                        labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown"))) %>% 
  mutate(malform = factor(malform,
                          levels = c(0, 1),
                          labels = c("abset", "present"))) %>% 
  mutate(mrace = factor(mrace,
                        levels = c(1, 2, 3, 4, 8),
                        labels = c("White", "Black", "Asian", "Puerto Rican", "Other")))
```

My proposed regression model for birthweight is based on hypothesized
factors. I hypothesize that the following factors will affect
birthweight:

-   `gaweeks`: gestational age in weeks - hypothesized to increase
    weight with greater age;
-   `malform`: presence of malformations that could affect weight -
    hypothesized to decrease weight;
-   `momage`: mother’s age at delivery (years) - hypothesized to
    decrease weight with greater mother age;
-   `wtgain`: mother’s weight gain during pregnancy (pounds) -
    hypothesized to increase birthweight with greater weight gain during
    pregnancy.

``` r
hyp_mod = lm(bwt ~ gaweeks + malform + momage + wtgain, data = birthweight_df)
main_fx_mod = lm(bwt ~ blength + gaweeks, data = birthweight_df)
interact_mod = lm(bwt ~ bhead + blength + babysex + (bhead * blength) + (bhead * babysex) + (bhead * blength * babysex), data = birthweight_df)

hyp_mod %>% broom::tidy()
```

    ## # A tibble: 5 × 5
    ##   term           estimate std.error statistic   p.value
    ##   <chr>             <dbl>     <dbl>     <dbl>     <dbl>
    ## 1 (Intercept)      241.      90.3       2.67  7.61e-  3
    ## 2 gaweeks           60.0      2.22     27.0   3.01e-148
    ## 3 malformpresent   -43.6    117.       -0.372 7.10e-  1
    ## 4 momage            14.8      1.80      8.21  2.83e- 16
    ## 5 wtgain             9.48     0.640    14.8   1.66e- 48

There are significant p-values here for some of my hypothesized
predictors. Particularly `gaweeks` and `wtgain` seem to have the most
statistically significant effects. Let’s look at some residuals for the
hypothesized model.

``` r
birthweight_df %>% 
  add_predictions(hyp_mod) %>% 
  add_residuals(hyp_mod) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(x = "Predicted Birthweight (grams)", y = "Residual", title = "Hypothesized Model Predictions vs Residuals")
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

![](p8105_hw6_tlm2152_files/figure-gfm/residuals%20predictions%20and%20plotting-1.png)<!-- -->

Most of the residuals seem to be fairly evenly dispersed about 0,
however there are some rather large differences. For instance some
predicted birthweights of 2000 grams have a residual of over 1000 grams.
We also seem to have more positive residuals on the low end of our
predictions and more negative residuals towards the maximum prediction,
which might be concerning for this model. Let’s take a look at a couple
of others and compare root mean squared error (RMSE).

``` r
cv_df <- 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
  mutate(
    hyp_model      = map(.x = train, ~lm(bwt ~ gaweeks + malform + momage + wtgain, data = .x)),
    main_fx_model  = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    interact_model = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + (bhead * blength) + (bhead * babysex) + (bhead * blength * babysex), data = .x))
    ) %>% 
  mutate(
    rmse_hyp      = map2_dbl(.x = hyp_model, .y = test, ~rmse(model = .x, data = .y)),
    rmse_main_fx  = map2_dbl(.x = main_fx_model, .y = test, ~rmse(model = .x, data = .y)),
    rmse_interact = map2_dbl(.x = interact_model, .y = test, ~rmse(model = .x, data = .y))
    )
```

``` r
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

![](p8105_hw6_tlm2152_files/figure-gfm/plotting%20RMSE%20for%20each%20model-1.png)<!-- -->

Based on the plot above, it looks like the hypothesized model has a much
higher RMSE compared to the other two. This lends credence to the idea
of using model diagnostics and data-driven model-building processes
rather than using hypotheses alone.

## Problem 2

Now, let’s look at bootstrapping with weather data from `rnoaa`.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: ~/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2021-12-02 20:22:36 (7.614)

    ## file min/max dates: 1869-01-01 / 2021-11-30

Next, I’ll use `bootstrap` to take 5000 samples with replacement of the
same size as the original data set.

``` r
set.seed(23)

boot_weather <- bootstrap(weather_df, 5000) %>% 
  rename(boot_sample = strap, boot_id = .id) %>% 
  mutate(boot_id = as.integer(boot_id))
```

``` r
as.data.frame(boot_weather$boot_sample[[1]])
```

    ## # A tibble: 365 × 6
    ##    name           id          date        prcp  tmax  tmin
    ##    <chr>          <chr>       <date>     <dbl> <dbl> <dbl>
    ##  1 CentralPark_NY USW00094728 2017-10-11    15  25    15.6
    ##  2 CentralPark_NY USW00094728 2017-09-05     0  29.4  20.6
    ##  3 CentralPark_NY USW00094728 2017-05-01     0  23.3   9.4
    ##  4 CentralPark_NY USW00094728 2017-06-20     8  28.3  21.7
    ##  5 CentralPark_NY USW00094728 2017-04-13     0  18.3   8.9
    ##  6 CentralPark_NY USW00094728 2017-10-28     0  20.6  12.8
    ##  7 CentralPark_NY USW00094728 2017-10-17     0  14.4   5.6
    ##  8 CentralPark_NY USW00094728 2017-05-29    33  16.1  13.3
    ##  9 CentralPark_NY USW00094728 2017-05-25   147  15    13.3
    ## 10 CentralPark_NY USW00094728 2017-06-13     0  34.4  25  
    ## # … with 355 more rows

And it looks like this has the correct number of rows and columns that
we would expect. Next, I’ll calculate *r̂*<sup>2</sup> or `r_squared` and
log (*β*<sub>0</sub> \* *β*<sub>1</sub>) or `log_var` for each bootstrap
sample.

``` r
boot_results <- 
  boot_weather %>% 
  mutate(
    models = map(boot_sample, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    glance = map(models, broom::glance)
  ) %>% 
  select(-boot_sample, -models) %>% 
  unnest(c(results, glance), names_repair = "unique") %>% 
  group_by(boot_id)
```

    ## New names:
    ## * statistic -> statistic...5
    ## * p.value -> p.value...6
    ## * statistic -> statistic...10
    ## * p.value -> p.value...11

``` r
boot_clean <- 
  boot_results %>% 
  select(boot_id, term, estimate, r.squared, adj.r.squared) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log_var = log(intercept * tmin))
```

``` r
r_sq_dist <- 
  boot_clean %>% 
  ggplot(aes(x = r_squared, fill = "brickred")) +
  geom_density(alpha = 0.2) +
  labs(title = "Distribution of r_squared") +
  theme(legend.position = "none") +
  stat_function(fun = dnorm,
                args = with(boot_clean, c(mean = mean(r_squared), sd = sd(r_squared))),
                color = "red",
                size = 1.5,
                alpha = .7)
  
log_var_dist <- 
  boot_clean %>% 
  ggplot(aes(x = log_var)) +
  geom_density(alpha = 0.2, fill = "dodgerblue1") +
  labs(title = "Distribution of log_var") +
  stat_function(fun = dnorm,
                args = with(boot_clean, c(mean = mean(log_var), sd = sd(log_var))),
                color = "blue",
                size = 1.5,
                alpha = .7)
  
r_sq_dist / log_var_dist
```

![](p8105_hw6_tlm2152_files/figure-gfm/bootstrap%20plots-1.png)<!-- -->

And when looking at the estimate distributions, they both look fairly
normal. I’ve included a normal distribution with the respective means
and standard deviations for comparison. One could argue that the
distributions are slightly left-skewed, but they are very close to
normal.

``` r
r_squared_bounds <- 
  quantile(pull(boot_clean, r_squared), probs = c(.025, 0.975), names = FALSE, type = 4)

log_var_bounds <- 
  quantile(pull(boot_clean, log_var), probs = c(.025, 0.975), names = FALSE, type = 4)

data.frame(estimate = c("r_squared", "log_var"),
          lower_bound = c(r_squared_bounds[[1]], log_var_bounds[[1]]),
          upper_bound = c(r_squared_bounds[[2]], log_var_bounds[[2]]))
```

    ##    estimate lower_bound upper_bound
    ## 1 r_squared   0.8934765   0.9275755
    ## 2   log_var   1.9640014   2.0582869

So the bounds of `r_squared` are 0.89 and 0.93. And the bounds of
`log_var` are 1.96 and 2.06. Now let’s look at the same distribution
plots with these bounds shown.

``` r
r_sq_dist <- 
  boot_clean %>% 
  ggplot(aes(x = r_squared, fill = "brickred")) +
  geom_density(alpha = 0.2) +
  labs(title = "Distribution of r_squared", y = "density") +
  theme(legend.position = "none") +
  stat_function(fun = dnorm,
                args = with(boot_clean, c(mean = mean(r_squared), sd = sd(r_squared))),
                color = "red",
                size = 1.5,
                alpha = .7) +
  geom_vline(xintercept = c(r_squared_bounds),
             linetype = "dashed")
  
log_var_dist <- 
  boot_clean %>% 
  ggplot(aes(x = log_var)) +
  geom_density(alpha = 0.2, fill = "dodgerblue1") +
  labs(title = "Distribution of log_var", y = "density") +
  stat_function(fun = dnorm,
                args = with(boot_clean, c(mean = mean(log_var), sd = sd(log_var))),
                color = "blue",
                size = 1.5,
                alpha = .7) +
    geom_vline(xintercept = c(log_var_bounds),
             linetype = "dashed")
  
r_sq_dist / log_var_dist
```

![](p8105_hw6_tlm2152_files/figure-gfm/plots%20with%20quantiles-1.png)<!-- -->

That’s nice.
